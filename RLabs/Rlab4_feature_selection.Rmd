---
title: "R Lab 5 - Feature Selection"
subtitle: "Machine Learning"
author: "Prof. Neylson Crepalde"
output: html_notebook
---

## Best Subset Selection

Vamos implementar utilizar o algoritmo do *Best Subset Selection* para testar o melhor ajuste no modelo que explica o Salário!

```{r setup}
library(ISLR)

# Verificando o banco de dados
data(Hitters)
names(Hitters)
dim(Hitters)

# Verificando os NAs
sum(is.na(Hitters$Salary))

# Retira os NAs
Hitters=na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
```



```{r bss}
library(leaps)
# Implementa o BSS
regfit.full=regsubsets(Salary~.,Hitters)

summary(regfit.full)

# Implementa o mesmo algoritmo para todas as possibilidades
regfit.full=regsubsets(Salary~.,data=Hitters,nvmax=19)

# Guarda a lista de resultados (summary)
reg.summary=summary(regfit.full)

# Verifica quais medidas de ajuste temos
names(reg.summary)
reg.summary$rsq

# Alguns gráficos de avaliação
par(mfrow=c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
which.max(reg.summary$adjr2)
points(11,reg.summary$adjr2[11], col="red",cex=2,pch=20)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
which.min(reg.summary$cp)
points(10,reg.summary$cp[10],col="red",cex=2,pch=20)
which.min(reg.summary$bic)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
points(6,reg.summary$bic[6],col="red",cex=2,pch=20)
plot(regfit.full,scale="r2")
plot(regfit.full,scale="adjr2")
plot(regfit.full,scale="Cp")
plot(regfit.full,scale="bic")
coef(regfit.full,6)
```





```{r Stepwise}
# Forward and Backward Stepwise Selection
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
summary(regfit.fwd)
regfit.bwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="backward")
summary(regfit.bwd)
```


```{r compare}
# Verifica os resultados dos 3 métodos
coef(regfit.full,7)
coef(regfit.fwd,7)
coef(regfit.bwd,7)
```



```{r choosing}
# Choosing Among Models
set.seed(1)
train=sample(c(TRUE,FALSE), nrow(Hitters),rep=TRUE)
test=(!train)
regfit.best=regsubsets(Salary~.,data=Hitters[train,],nvmax=19)
test.mat=model.matrix(Salary~.,data=Hitters[test,])
val.errors=rep(NA,19)
for(i in 1:19){
   coefi=coef(regfit.best,id=i)
   pred=test.mat[,names(coefi)]%*%coefi
   val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
which.min(val.errors)
coef(regfit.best,10)

# Função de predict para regsubsets
predict.regsubsets=function(object,newdata,id,...){
  form=as.formula(object$call[[2]])
  mat=model.matrix(form,newdata)
  coefi=coef(object,id=id)
  xvars=names(coefi)
  mat[,xvars]%*%coefi
  }

regfit.best=regsubsets(Salary~.,data=Hitters,nvmax=19)
# Verificando os coeficientes do modelo com melhor ajuste
coef(regfit.best,10)
```




```{r cv}
# Usando 10-Fold Cross Validation para verificar o melhor modelo
k=10
set.seed(1)
# Atribuir cada caso a um fold (um pedaço)
folds=sample(1:k,nrow(Hitters),replace=TRUE) 

# Monta uma matriz vazia para conter os erros dos 10 folds
# Matriz com k linhas (folds) e 19 colunas (uma para cada variável)
cv.errors = matrix(NA, k, 19, dimnames=list(NULL, paste(1:19)))

# Executa o CV

for(j in 1:k){  # Para cada rodada de 1 até 10 (FOLDS)
  best.fit=regsubsets(Salary~.,data=Hitters[folds!=j,],nvmax=19) # Roda o BSS em tudo menos o test
  for(i in 1:19){  # para cada variável das 19 presentes
    # Prediz o erro para cada quantidade de variáveis (de 1 a 19)
    pred=predict(best.fit,Hitters[folds==j,],id=i)
    # guarda a média do erro na célula adequada da matriz
    cv.errors[j,i]=mean( (Hitters$Salary[folds==j]-pred)^2) 
     }
}

# Tira a média do erro dos 10 folds para cada número de variáveis
mean.cv.errors=apply(cv.errors,2,mean)
mean.cv.errors
which.min(mean.cv.errors) # Melhor quantidade de variáveis

# Plota
par(mfrow=c(1,1))
plot(mean.cv.errors,type='b')
reg.best=regsubsets(Salary~.,data=Hitters, nvmax=19)
coef(reg.best,11) # Melhor modelo
```

